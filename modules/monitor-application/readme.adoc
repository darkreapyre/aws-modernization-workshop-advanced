= Digital Modernization

:imagesdir: ../../images
:icons: font

== Monitoring the Application

****
*Expected Outcome:*

* 200 level understanding of Container Healthchecks using EKS.
* 200 level understanding of shipping container logs for to CloudWatch.

*Lab Requirements:*

* Clou9 IDE.
* Amazon Elastic Container Service for Kubernetes Cluster.

*Average Lab Time:* 
45 minutes
****

=== Introduction
When it comes to monitoring an application, a key concept to understand is you need to ensure that the application is working rather than only looking to see if server or container is running. In this module, we will go over some key concepts in monitoring and logging and how to integrate those concepts with our Pet Store application. The module will focus on Monitoring Healthchecks and leveraging them further using link:https://aws.amazon.com/cloudwatch/[Amazon Cloudwatch].

NOTE: The following section of the module assumes a working EKS cluster, created in the *Modern Container Applicaiton on EKS* module.

=== Healthchecks in Amazon EKS
By default, Kubernetes will restart a container if it crashes for any reason. It uses Liveness and Readiness probes which can be configured for running a robust application by identifying the healthy containers to send traffic to and restarting the ones when required.

In this section, we will understand how link:https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[liveness and readiness probes] are defined and test the same against different states of a pod. Below is the high level description of how these probes work.

* *Liveness probes* are used in Kubernetes to know when a pod is alive or dead. A pod can be in a dead state for different reasons while Kubernetes kills and recreates the pod when liveness probe does not pass.
* *Readiness probes* are used in Kubernetes to know when a pod is ready to serve traffic. Only when the readiness probe passes, a pod will receive traffic from the service. When readiness probe fails, traffic will not be sent to a pod until it passes.

We will review some examples in this module to understand different options for configuring liveness and readiness probes.

==== Configuring the Liveness Probe
As with any Amazon EKS or Kubernetes cluster, we will use manifest file to decelaritively deploy a simple liveness probe.

Step 1:: In the Cloud9 IDE `terminal`, ensure you have switched to this modules' working directory.
+
[source,shell]
----
cd ~/environment/aws-modernization-workshop-advanced/modules/monitor-application/
----
+
Step 2:: Open the `liveness-app.yaml` file by double clicking the filename in the lefthand navigation of the Cloud9 IDE. The file has the following contents:
+
[source,yaml]
----
apiVersion: v1
kind: Pod
metadata:
  name: liveness-app
spec:
  containers:
  - name: liveness
    image: brentley/ecsdemo-nodejs
    livenessProbe:
      httpGet:
        path: /health
        port: 3000
      initialDelaySeconds: 5
      periodSeconds: 5
----
+
Step 3:: Apply the manifest by running this command in your Cloud9 IDE `terminal`:
+
[source,shell]
----
kubectl apply -f liveness-app.yaml
----
+
Expected Output:
+
[.output]
....
pod/liveness-app created
....
+
Step 4:: Confirm that the pod is running by executing the following command:
+
[source,shell]
----
kubectl get pod liveness-app
----
+
Expected Output:
+
[.output]
----
NAME           READY   STATUS    RESTARTS   AGE
liveness-app   1/1     Running   0          6s
----
+
NOTE: The number of `RESTARTS` is `0`.
+
step 5:: Use `kubectl describe` command will show an event history which will show any probe failures or restarts, as follows:
+
[source,shell]
----
kubectl describe pod liveness-app | grep -A20 Events
----
+
Expected Output:
+
[.output]
----
  Type    Reason     Age   From                                                  Message
  ----    ------     ----  ----                                                  -------
  Normal  Scheduled  22s   default-scheduler                                     Successfully assigned default/liveness-app to ip-192-168-84-75.us-west-2.compute.internal
  Normal  Pulling    22s   kubelet, ip-192-168-84-75.us-west-2.compute.internal  pulling image "brentley/ecsdemo-nodejs"
  Normal  Pulled     21s   kubelet, ip-192-168-84-75.us-west-2.compute.internal  Successfully pulled image "brentley/ecsdemo-nodejs"
  Normal  Created    21s   kubelet, ip-192-168-84-75.us-west-2.compute.internal  Created container
  Normal  Started    20s   kubelet, ip-192-168-84-75.us-west-2.compute.internal  Started container
----
+
Step 6:: We will now introduce a failure inside the docker runtime by sending the `kill` command, as follows:
+
[source,shell]
----
kubectl exec -it liveness-app -- /bin/kill -s SIGUSR1 1
----
+
Step 7:: After 15-20 seconds, re-run the `kubectl describe` command to view the `Events` output again and see what atctions the `kubelet` took.
+
Expected Output:
+
[.output]
----
  Type     Reason     Age                From                                                  Message
  ----     ------     ----               ----                                                  -------
  Normal   Scheduled  72s                default-scheduler                                     Successfully assigned default/liveness-app to ip-192-168-84-75.us-west-2.compute.internal
  Warning  Unhealthy  36s (x3 over 46s)  kubelet, ip-192-168-84-75.us-west-2.compute.internal  Liveness probe failed: Get http://192.168.85.179:3000/health: net/http: request canceled (Client.Timeout exceeded while awaiting headers)
  Normal   Pulling    6s (x2 over 71s)   kubelet, ip-192-168-84-75.us-west-2.compute.internal  pulling image "brentley/ecsdemo-nodejs"
  Normal   Killing    6s                 kubelet, ip-192-168-84-75.us-west-2.compute.internal  Killing container with id docker://liveness:Container failed liveness probe.. Container will be killed and recreated.
  Normal   Pulled     5s (x2 over 70s)   kubelet, ip-192-168-84-75.us-west-2.compute.internal  Successfully pulled image "brentley/ecsdemo-nodejs"
  Normal   Created    5s (x2 over 70s)   kubelet, ip-192-168-84-75.us-west-2.compute.internal  Created container
  Normal   Started    5s (x2 over 70s)   kubelet, ip-192-168-84-75.us-west-2.compute.internal  Started container
----
+
TIP: When the nodejs application entered a debug mode with `SIGUSR1` signal, it did not respond to the health check pings and the `kubelet` killed the container. The container was subject to the default restart policy.
+
Step 8:: Confirm that the container was restarted by viewing the pod.
+
[source,shell]
----
kubectl get pod liveness-app
----
+
Expected Output:
+
[.output]
----
NAME           READY   STATUS    RESTARTS   AGE
liveness-app   1/1     Running   1          6m42s
----
+
NOTE: The number of `RESTARTS` is now `1`.

==== Configuring the Readiness Probe
The `readinessProbe` definition explains how a linux command can be configured as healthcheck. We create an empty file called `/tmp/healthy`, to configure readiness probe and use the same to understand how kubelet helps to update a deployment with only healthy pods.

Step 1:: Open the `readiness-deployment.yaml` file by double clicking the filename in the lefthand navigation of the Cloud9 IDE. The file has the following contents:
+
[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: readiness-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: readiness-deployment
  template:
    metadata:
      labels:
        app: readiness-deployment
    spec:
      containers:
      - name: readiness-deployment
        image: alpine
        command: ["sh", "-c", "touch /tmp/healthy && sleep 86400"]
        readinessProbe:
          exec:
            command:
            - cat
            - /tmp/healthy
          initialDelaySeconds: 5
          periodSeconds: 3
----
+
Step 2:: We now create a deployment to test the readiness probe using the `terminal` in our CLoud9 IDE. The deployment consists of 3 replicas of the readiness probe.
+
[source,shell]
----
kubectl apply -f readiness-deployment.yaml
----
+
Step 3:: View the deployment by executing the folloing `kubectl` command:
+
[source,shell]
----
kubectl get pods -l app=readiness-deployment
----
+
Expected Output:
+
[.output]
----
NAME                                    READY   STATUS    RESTARTS   AGE
readiness-deployment-6b95b8dd66-dqdzq   0/1     Running   0          8s
readiness-deployment-6b95b8dd66-tpxll   0/1     Running   0          8s
readiness-deployment-6b95b8dd66-x2mwn   0/1     Running   0          8s
----
+
Step 4:: Confirm that all replicas are available to serve traffic when a service is pointed to this deployment.
+
[source,shell]
----
kubectl describe deployment readiness-deployment | grep Replicas:
----
+
Expected Output:
+
[.output]
----
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
----
+
Step 5:: We will now introduce a failure inside the docker runtime by deleting the `/tmp/healthy` file inside the docker runtime, since this file must be present in order for the readiness check to pass. Pick one of the 3 available pods from the output of *Step 4* to introduce a failure. Exeecute the following command, substituing the name of the pod you've selected:
+
[source,shell]
----
kubectl exec -it <YOUR-READINESS-POD-NAME> -- rm /tmp/healthy
----
+
Step 6:: View the deployment once again by running the following command:
+
[source,shell]
----
kubectl get pods -l app=readiness-deployment
----
+
Expected Output:
+
[.output]
----
NAME                                    READY   STATUS    RESTARTS   AGE
readiness-deployment-6b95b8dd66-74msx   0/1     Running   0          53s
readiness-deployment-6b95b8dd66-k99vl   1/1     Running   0          53s
readiness-deployment-6b95b8dd66-pwcgc   1/1     Running   0          53s
----
+
NOTE: Traffic will not be routed to the first pod in the above deployment. The `READY` column confirms that the readiness probe for this pod did not pass and hence was marked as not ready. 
+
Step 7:: We will now check for the replicas that are available to serve traffic when a service is pointed to this deployment.
+
[source,shell]
----
 kubectl describe deployment readiness-deployment | grep Replicas:
----
+
Expected Output:
+
[.output]
----
Replicas:               3 desired | 3 updated | 3 total | 2 available | 1 unavailable
----
+
When the readiness probe for a pod fails, the endpoints controller removes the pod from list of endpoints of all services that match the pod.
+
TIP: Our Liveness Probe example used `HTTP` request and Readiness Probe executed a command to check health of a pod. Same can be accomplished using a `TCP` request as described in the link:https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[documentation].

*Challenge Question:* _How would you restore the pod to Ready status?_

+++ <details><summary> +++
Solution:
+++ </summary><div> +++
Run the below command with the name of the pod to recreate the `/tmp/healthy file`. Once the pod passes the probe, it gets marked as ready and will begin to receive traffic again.

[source,shell]
----
kubectl exec -it <YOUR-READINESS-POD-NAME> -- touch /tmp/healthy

kubectl get pods -l app=readiness-deployment
----
+++ </div></details> +++

=== Understanding Shipping Logs to CloudWatch from EKS
A typical logging patern in Kubernetes, and hence EKS is to leverage a pattern known as the *EFK stack*, which is comprised of:

* link:https://www.fluentd.org/[Fluentd]
* link:https://www.elastic.co/products/elasticsearch[Elasticsearch]
* link:https://www.elastic.co/products/kibana[Kibana]

However, in this part of the module, we will only focus on *Fluentd* as it will be the mechanism that forwards the logs from the indivudual worker nodes in the cluster to the central loggin backend, CkoudWatch. We will be deploying Fluentd as a DaemonSet, or one pod per worker node. The fluentd log daemon will collect logs and forward to CloudWatch Logs. This will require the nodes to have permissions to send logs and create log groups and log streams.

Step 1:: For this part of the module we will need to ensure that the `Role Name` that the EKS worker nodes use has the necessary policy. Execute the following commands in the CLoud9 IDE `terminal` to configure the worker roles varaibales:
+
[source,shell]
----
INSTANCE_PROFILE_NAME=$(aws iam list-instance-profiles | jq -r '.InstanceProfiles[].InstanceProfileName' | grep nodegroup)

INSTANCE_PROFILE_ARN=$(aws iam get-instance-profile --instance-profile-name $INSTANCE_PROFILE_NAME | jq -r '.InstanceProfile.Arn')

ROLE_NAME=$(aws iam get-instance-profile --instance-profile-name $INSTANCE_PROFILE_NAME | jq -r '.InstanceProfile.Roles[] | .RoleName')

echo "export ROLE_NAME=${ROLE_NAME}" >> ~/.bash_profile

echo "export INSTANCE_PROFILE_ARN=${INSTANCE_PROFILE_ARN}" >> ~/.bash_profile
----
+
Step 2:: Next we configure a policy for CloudWatch access and apply it to the worker nodes.
+
[source,shell]
----
cat <<EoF > /tmp/eks-logs-policy.json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": [
                "logs:DescribeLogGroups",
                "logs:DescribeLogStreams",
                "logs:CreateLogGroup",
                "logs:CreateLogStream",
                "logs:PutLogEvents"
            ],
            "Resource": "*",
            "Effect": "Allow"
        }
    ]
}
EoF

aws iam put-role-policy --role-name $ROLE_NAME --policy-name Logs-Policy-For-Worker --policy-document file:///tmp/eks-logs-policy.json
----
+
Steo 3:: Validate that the policy has been attached to the worker node role.
+
[source,shell]
----
aws iam get-role-policy --role-name $ROLE_NAME --policy-name Logs-Policy-For-Worker
----
+
Expected Output:
+
[.output]
----
{
    "RoleName": "eksctl-petstore-nodegroup-ng-d389-NodeInstanceRole-1E8S9YL9EQ5QI", 
    "PolicyDocument": {
        "Version": "2012-10-17", 
        "Statement": [
            {
                "Action": [
                    "logs:DescribeLogGroups", 
                    "logs:DescribeLogStreams", 
                    "logs:CreateLogGroup", 
                    "logs:CreateLogStream", 
                    "logs:PutLogEvents"
                ], 
                "Resource": "*", 
                "Effect": "Allow"
            }
        ]
    }, 
    "PolicyName": "Logs-Policy-For-Worker"
}
----
+
Step 4:: Now we can deploy Fluentd. To get started, navigate to the folder for this module and open the `fluentd.yaml` in the Cloud9 IDE. Although it is a large manifest for deploying Fluentd as a *DaemonSet*, i.e. one pod per worker node, the log agent configuration is located in the Kubernetes *ConfigMap* as shown below:
+
[source,yaml]
----
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
  labels:
    k8s-app: fluentd-cloudwatch
data:
  fluent.conf: |
    @include containers.conf
    @include systemd.conf

    <match fluent.**>
      @type null
    </match>
  containers.conf: |
    <source>
      @type tail
      @id in_tail_container_logs
      @label @containers
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag *
      read_from_head true
      <parse>
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

    <label @containers>
      <filter **>
        @type kubernetes_metadata
        @id filter_kube_metadata
      </filter>

      <filter **>
        @type record_transformer
        @id filter_containers_stream_transformer
        <record>
          stream_name ${tag_parts[3]}
        </record>
      </filter>

      <match **>
        @type cloudwatch_logs
        @id out_cloudwatch_logs_containers
        region "#{ENV.fetch('REGION')}"
        log_group_name "/eks/#{ENV.fetch('CLUSTER_NAME')}/containers"
        log_stream_name_key stream_name
        remove_log_stream_name_key true
        auto_create_stream true
        <buffer>
          flush_interval 5
          chunk_limit_size 2m
          queued_chunks_limit_size 32
          retry_forever true
        </buffer>
      </match>
    </label>
  systemd.conf: |
    <source>
      @type systemd
      @id in_systemd_kubelet
      @label @systemd
      filters [{ "_SYSTEMD_UNIT": "kubelet.service" }]
      <entry>
        field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
        field_map_strict true
      </entry>
      path /run/log/journal
      pos_file /var/log/fluentd-journald-kubelet.pos
      read_from_head true
      tag kubelet.service
    </source>

    <source>
      @type systemd
      @id in_systemd_kubeproxy
      @label @systemd
      filters [{ "_SYSTEMD_UNIT": "kubeproxy.service" }]
      <entry>
        field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
        field_map_strict true
      </entry>
      path /run/log/journal
      pos_file /var/log/fluentd-journald-kubeproxy.pos
      read_from_head true
      tag kubeproxy.service
    </source>

    <source>
      @type systemd
      @id in_systemd_docker
      @label @systemd
      filters [{ "_SYSTEMD_UNIT": "docker.service" }]
      <entry>
        field_map {"MESSAGE": "message", "_HOSTNAME": "hostname", "_SYSTEMD_UNIT": "systemd_unit"}
        field_map_strict true
      </entry>
      path /run/log/journal
      pos_file /var/log/fluentd-journald-docker.pos
      read_from_head true
      tag docker.service
    </source>

    <label @systemd>
      <filter **>
        @type record_transformer
        @id filter_systemd_stream_transformer
        <record>
          stream_name ${tag}-${record["hostname"]}
        </record>
      </filter>

      <match **>
        @type cloudwatch_logs
        @id out_cloudwatch_logs_systemd
        region "#{ENV.fetch('REGION')}"
        log_group_name "/eks/#{ENV.fetch('CLUSTER_NAME')}/systemd"
        log_stream_name_key stream_name
        auto_create_stream true
        remove_log_stream_name_key true
        <buffer>
          flush_interval 5
          chunk_limit_size 2m
          queued_chunks_limit_size 32
          retry_forever true
        </buffer>
      </match>
    </label>
---
----
+
Step 5:: Apply the manifest to create the fluentd DaemonSet.
+
NOTE: Ensure that you are working in this modules directory. i.e. `~/environment/aws-modernization-workshop-advanced/modules/monitor-application/eks`
+
[source,shell]
----
kubectl apply -f fluentd.yml
----
+
Step 6:: We can confirm that all the pods chnage to `Running` status by executing the following command:
+
[source,shell]
----
kubectl get pods -w --namespace=kube-system
----
+
Ecpected Output:
+
[.output]
----
NAME                       READY   STATUS    RESTARTS   AGE
aws-node-k75kc             1/1     Running   0          4h
aws-node-w9d7n             1/1     Running   0          4h
coredns-6fdd4f6856-mvlst   1/1     Running   0          4h6m
coredns-6fdd4f6856-xzc9x   1/1     Running   0          4h6m
fluentd-cloudwatch-55p6x   1/1     Running   0          21s
fluentd-cloudwatch-sn25n   1/1     Running   0          21s
kube-proxy-hgmvw           1/1     Running   0          4h
kube-proxy-r84rb           1/1     Running   0          4h
----
+
Step 7:: Now we can view the CloudWatch log streams for the containers in our `kube-system`. To do this, open a browser tab and navigate to the link:https://us-west-2.console.aws.amazon.com/cloudwatch/[CloudWatch Console] and click *Logs* in the navigation pane. All the CloudWatch Log Groups will be displayed.
+
Step 8:: In the *Filter:* box, enter `eks` and press `[ENTER]` to filter the Log Group for our EKS cluster. Click on the `/eks/petstore/containers` Log Group.
+
image:cw-logs.png[Log Group]
+
Now we can see all the logs for the various containers in our `kube-system`.
+
image:cw-streams.png[CloudWatch Streams]

This conludes the *Application Monitoring* module. Please continue to the next module.